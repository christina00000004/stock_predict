import torch
import torch.nn.functional as F
from src.model import StockPredictor
from src.data import StockNetDataModule
import lightning as L
from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping
import numpy as np
import os
import shutil
import json
from datetime import datetime


class ClassificationStockPredictor(StockPredictor):
    """ä¸‰åˆ†ç±»è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ - é¢„æµ‹æ¶¨è·Œå¹³"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # ä¿®æ”¹è¾“å‡ºå±‚ä¸º3åˆ†ç±»ï¼ˆæ¶¨ã€è·Œã€å¹³ï¼‰
        self.head = torch.nn.Sequential(
            torch.nn.Linear(self.d_hidden, self.d_hidden // 2),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3),
            torch.nn.Linear(self.d_hidden // 2, 3)  # 3åˆ†ç±»
        )
    
    def step(self, batch, mode='train'):
        x_ts, x_emb, x_id, targets = batch
        predictions = self.forward(x_ts, x_emb, x_id)
        
        # å¤„ç†æ ‡ç­¾ç»´åº¦ï¼štargetsæ˜¯[batch_size, num_stocks]ï¼Œéœ€è¦å±•å¹³
        batch_size, num_stocks = targets.shape
        targets_flat = targets.flatten()  # [batch_size * num_stocks]
        predictions_flat = predictions.view(-1, predictions.size(-1))  # [batch_size * num_stocks, num_classes]
        
        # å°†è¿ç»­æ ‡ç­¾è½¬æ¢ä¸ºåˆ†ç±»æ ‡ç­¾ï¼ˆ3å¤©å¹³å‡æ”¶ç›Šçš„é˜ˆå€¼ï¼‰
        class_targets = torch.zeros_like(targets_flat, dtype=torch.long)
        class_targets[targets_flat > 1.0] = 0  # æ¶¨ï¼ˆ3å¤©å¹³å‡æ¶¨å¹…>1%ï¼‰
        class_targets[targets_flat < -1.0] = 1  # è·Œï¼ˆ3å¤©å¹³å‡è·Œå¹…>1%ï¼‰
        class_targets[(targets_flat >= -1.0) & (targets_flat <= 1.0)] = 2  # å¹³ï¼ˆ-1%åˆ°1%ä¹‹é—´ï¼‰
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        loss = F.cross_entropy(predictions_flat, class_targets)
        
        # è®¡ç®—å‡†ç¡®ç‡
        pred_classes = torch.argmax(predictions_flat, dim=1)
        accuracy = (pred_classes == class_targets).float().mean()
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
        class_accuracies = []
        for i in range(3):
            mask = (class_targets == i)
            if mask.sum() > 0:
                class_acc = (pred_classes[mask] == class_targets[mask]).float().mean()
                class_accuracies.append(class_acc.item())
            else:
                class_accuracies.append(0.0)
        
        # è®°å½•æŒ‡æ ‡
        self.log(f"{mode}_loss", loss.item())
        self.log(f"{mode}_accuracy", accuracy.item())
        self.log(f"{mode}_class_0_acc", class_accuracies[0])  # æ¶¨çš„å‡†ç¡®ç‡
        self.log(f"{mode}_class_1_acc", class_accuracies[1])  # è·Œçš„å‡†ç¡®ç‡
        self.log(f"{mode}_class_2_acc", class_accuracies[2])  # å¹³çš„å‡†ç¡®ç‡
        
        return loss


def save_model_for_inference(model, save_dir="saved_models_classification_3day"):
    """ä¿å­˜æ¨¡å‹ç”¨äºæ¨ç†"""
    os.makedirs(save_dir, exist_ok=True)
    
    # ä¿å­˜æ¨¡å‹æƒé‡
    model_path = os.path.join(save_dir, "classification_model_3day.pth")
    torch.save(model.state_dict(), model_path)
    print(f"ğŸ’¾ æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ°: {model_path}")
    
    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    model_info = {
        "model_type": "ClassificationStockPredictor",
        "description": "ä¸‰åˆ†ç±»è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ï¼ˆæ¶¨/è·Œ/å¹³ï¼‰- 3å¤©çª—å£",
        "input_features": 6,  # OHLCV + æŠ€æœ¯æŒ‡æ ‡
        "embedding_dim": 768,  # BERTåµŒå…¥ç»´åº¦
        "hidden_dim": 128,     # éšè—å±‚ç»´åº¦
        "num_classes": 3,      # åˆ†ç±»æ•°é‡
        "context_window": 3,  # æ—¶é—´çª—å£
        "label_type": "3day_avg",  # æ ‡ç­¾ç±»å‹
        "classification_thresholds": {
            "up": 1.0,      # æ¶¨ç±»é˜ˆå€¼
            "down": -1.0,   # è·Œç±»é˜ˆå€¼
            "flat": [-1.0, 1.0]  # å¹³ç±»é˜ˆå€¼èŒƒå›´
        },
        "class_names": ["æ¶¨", "è·Œ", "å¹³"],
        "class_descriptions": [
            "3å¤©å¹³å‡æ”¶ç›Š > 1%",
            "3å¤©å¹³å‡æ”¶ç›Š < -1%", 
            "3å¤©å¹³å‡æ”¶ç›Šåœ¨ -1% åˆ° 1% ä¹‹é—´"
        ],
        "training_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "model_parameters": model.count_parameters()
    }
    
    info_path = os.path.join(save_dir, "model_info.json")
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_path}")
    
    return model_path, info_path


def create_inference_script(save_dir="saved_models_classification_3day"):
    """åˆ›å»ºæ¨ç†è„šæœ¬"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    script_path = os.path.join(save_dir, f"inference_classification_3day_{timestamp}.py")
    
    script_content = '''import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import json
import os
from src.model import StockPredictor


class ClassificationStockPredictor(StockPredictor):
    """ä¸‰åˆ†ç±»è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ï¼šæ¶¨/è·Œ/å¹³"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # ä¿®æ”¹è¾“å‡ºå±‚ä¸º3åˆ†ç±»
        self.head = nn.Sequential(
            nn.Linear(self.d_hidden, self.d_hidden // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(self.d_hidden // 2, 3)  # 3åˆ†ç±»ï¼šæ¶¨/è·Œ/å¹³
        )
    
    def predict(self, x_ts, x_emb, x_id):
        """é¢„æµ‹å‡½æ•°"""
        self.eval()
        with torch.no_grad():
            predictions = self.forward(x_ts, x_emb, x_id)
            probabilities = F.softmax(predictions, dim=-1)
            predicted_classes = torch.argmax(predictions, dim=-1)
            return predicted_classes, probabilities


def load_model(model_path, model_info_path):
    """åŠ è½½æ¨¡å‹"""
    # è¯»å–æ¨¡å‹ä¿¡æ¯
    with open(model_info_path, 'r', encoding='utf-8') as f:
        model_info = json.load(f)
    
    # åˆ›å»ºæ¨¡å‹
    model = ClassificationStockPredictor(
        n_features=model_info["input_features"],
        d_emb=model_info["embedding_dim"],
        d_hidden=model_info["hidden_dim"],
        max_ids=87,
        n_blocks=4,
        d_head=model_info["hidden_dim"] // 4,
        n_head=4,
        dropout=0.3,
        use_linear_att=True,
        rotary_emb_list=[2],
        ignore_list=None,
        mode=0,
        lr=5e-5,
        weight_decay=1e-4
    )
    
    # åŠ è½½æƒé‡
    model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.eval()
    
    return model, model_info


def predict_stock_movement(model, model_info, timeseries_data, embedding_data, stock_id):
    """é¢„æµ‹è‚¡ç¥¨èµ°åŠ¿"""
    # æ•°æ®é¢„å¤„ç†ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´ï¼‰
    # timeseries_data: [context_window, n_features]
    # embedding_data: [context_window, embedding_dim]
    # stock_id: è‚¡ç¥¨ID
    
    # è½¬æ¢ä¸ºtensor
    x_ts = torch.tensor(timeseries_data, dtype=torch.float32).unsqueeze(0)  # [1, context_window, n_features]
    x_emb = torch.tensor(embedding_data, dtype=torch.float32).unsqueeze(0)  # [1, context_window, embedding_dim]
    x_id = torch.tensor([stock_id], dtype=torch.long)  # [1]
    
    # é¢„æµ‹
    predicted_classes, probabilities = model.predict(x_ts, x_emb, x_id)
    
    # è·å–ç»“æœ
    class_idx = predicted_classes.item()
    class_name = model_info["class_names"][class_idx]
    class_description = model_info["class_descriptions"][class_idx]
    confidence = probabilities[0][class_idx].item()
    
    return {
        "prediction": class_name,
        "class_index": class_idx,
        "description": class_description,
        "confidence": confidence,
        "probabilities": {
            "æ¶¨": probabilities[0][0].item(),
            "è·Œ": probabilities[0][1].item(),
            "å¹³": probabilities[0][2].item()
        }
    }


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    # æ¨¡å‹è·¯å¾„
    model_path = "classification_model_3day.pth"
    model_info_path = "model_info.json"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ¤– åŠ è½½ä¸‰åˆ†ç±»æ¨¡å‹ï¼ˆ3å¤©çª—å£ï¼‰...")
    model, model_info = load_model(model_path, model_info_path)
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print(f"ğŸ“Š æ¨¡å‹ç±»å‹: {model_info['model_type']}")
    print(f"ğŸ“Š æ¨¡å‹æè¿°: {model_info['description']}")
    print(f"ğŸ“Š è®­ç»ƒæ—¥æœŸ: {model_info['training_date']}")
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {model_info['model_parameters']:,}")
    
    # ç¤ºä¾‹é¢„æµ‹ï¼ˆéœ€è¦å®é™…æ•°æ®ï¼‰
    print("\\nğŸ“ˆ ç¤ºä¾‹é¢„æµ‹:")
    print("æ³¨æ„ï¼šéœ€è¦æä¾›å®é™…çš„timeseries_dataã€embedding_dataå’Œstock_id")
    print("è°ƒç”¨ predict_stock_movement(model, model_info, timeseries_data, embedding_data, stock_id)")
    
    # ç¤ºä¾‹æ•°æ®ç»“æ„
    print("\\nğŸ“‹ è¾“å…¥æ•°æ®æ ¼å¼:")
    print("- timeseries_data: [3, 6] - 3å¤©çª—å£ï¼Œ6ä¸ªç‰¹å¾ï¼ˆOHLCV+æŠ€æœ¯æŒ‡æ ‡ï¼‰")
    print("- embedding_data: [3, 768] - 3å¤©çª—å£ï¼Œ768ç»´BERTåµŒå…¥")
    print("- stock_id: æ•´æ•° - è‚¡ç¥¨ID")


if __name__ == "__main__":
    main()
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"ğŸ“ æ¨ç†è„šæœ¬å·²åˆ›å»º: {script_path}")
    return script_path


def train_model():
    """è®­ç»ƒä¸‰åˆ†ç±»æ¨¡å‹"""
    print("å¼€å§‹è®­ç»ƒä¸‰åˆ†ç±»æ¨¡å‹ï¼ˆ3å¤©çª—å£ï¼‰...")
    
    # é…ç½®
    d_hidden = 128
    n_head = 4
    n_blocks = 4
    dropout = 0.3
    learning_rate = 5e-5
    batch_size = 16
    context_window = 3  # ä½¿ç”¨3å¤©çª—å£
    label_type = '3day_avg'  # ä½¿ç”¨3å¤©å¹³å‡æ”¶ç›Š
    
    data_path = 'D:/Multimodal-Stock-Prediction2'
    
    # ä½¿ç”¨æ”¹è¿›çš„åµŒå…¥æ–‡ä»¶
    improved_embeddings_path = os.path.join(data_path, 'stocknet-dataset', 'embeddings', 'google-bert-bert-base-uncased_improved.npy')
    if os.path.exists(improved_embeddings_path):
        print("ğŸ“ ä½¿ç”¨æ”¹è¿›çš„åµŒå…¥æ–‡ä»¶...")
        original_embeddings_path = os.path.join(data_path, 'all_embeddings.npy')
        shutil.copy2(improved_embeddings_path, original_embeddings_path)
        print("âœ… æ”¹è¿›çš„åµŒå…¥æ–‡ä»¶å·²å¤åˆ¶åˆ°åŸå§‹ä½ç½®")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°æ”¹è¿›çš„åµŒå…¥æ–‡ä»¶ï¼Œä½¿ç”¨åŸå§‹åµŒå…¥")
    
    # ä½¿ç”¨ä¿®æ”¹åçš„æ•°æ®æ¨¡å—
    datamod = StockNetDataModule(
        data_path=data_path,
        context_window=context_window,
        batch_size=batch_size,
        min_active_stock=1,
        a_threshold=0.0002,
        b_threshold=0.0055,
        num_workers=2,
        label_type=label_type  # ä½¿ç”¨3å¤©å¹³å‡æ”¶ç›Š
    )
    
    # åˆ›å»ºä¸‰åˆ†ç±»æ¨¡å‹
    model = ClassificationStockPredictor(
        n_features=6,  # åŸå§‹ç‰¹å¾æ•°é‡
        d_emb=768,
        d_hidden=d_hidden,
        max_ids=87,
        n_blocks=n_blocks,
        d_head=d_hidden // n_head,
        n_head=n_head,
        dropout=dropout,
        use_linear_att=True,
        rotary_emb_list=[2],
        ignore_list=None,
        mode=0,
        lr=learning_rate,
        weight_decay=1e-4
    )
    
    print(f'ğŸ“ˆ æ¨¡å‹å‚æ•°æ•°é‡: {model.count_parameters():,}')
    
    # æ£€æŸ¥ç‚¹å›è°ƒ
    experiment_name = "classification_model_3day"
    checkpoint_callback = ModelCheckpoint(
        dirpath=f"experiments/{experiment_name}/weights",
        filename="best-epoch={epoch:02d}-val_accuracy={val_accuracy:.4f}",
        save_top_k=3,
        monitor="val_accuracy",
        mode="max"
    )
    
    early_stop_callback = EarlyStopping(
        monitor="val_accuracy", 
        min_delta=0.001, 
        patience=20, 
        verbose=True, 
        mode="max"
    )
    
    trainer = L.Trainer(
        max_epochs=100,
        accelerator="auto",
        devices="auto",
        callbacks=[checkpoint_callback, early_stop_callback],
        gradient_clip_val=0.5,
        enable_progress_bar=True,
        log_every_n_steps=10,
        accumulate_grad_batches=1,
        precision="16-mixed" if torch.cuda.is_available() else "32"
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸš€ å¼€å§‹è®­ç»ƒä¸‰åˆ†ç±»æ¨¡å‹ï¼ˆ3å¤©çª—å£ï¼‰...")
    print(f"ğŸ“Š æ ‡ç­¾ç±»å‹: {label_type}")
    print(f"ğŸ¯ åˆ†ç±»é˜ˆå€¼: æ¶¨(>1%), è·Œ(<-1%), å¹³(-1%~1%)")
    
    # è®­ç»ƒæ¨¡å‹
    trainer.fit(model, datamodule=datamod)
    
    # æµ‹è¯•æ¨¡å‹
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹...")
    results = trainer.test(ckpt_path='best', datamodule=datamod)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("ğŸ‰ ä¸‰åˆ†ç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼ˆ3å¤©çª—å£ï¼‰ï¼")
    print("="*60)
    
    test_result = results[0]
    print(f"ğŸ“Š æµ‹è¯•å‡†ç¡®ç‡: {test_result['test_accuracy']:.4f}")
    print(f"ğŸ“Š æµ‹è¯•æŸå¤±: {test_result['test_loss']:.4f}")
    print(f"ğŸ“Š æ¶¨ç±»å‡†ç¡®ç‡: {test_result['test_class_0_acc']:.4f}")
    print(f"ğŸ“Š è·Œç±»å‡†ç¡®ç‡: {test_result['test_class_1_acc']:.4f}")
    print(f"ğŸ“Š å¹³ç±»å‡†ç¡®ç‡: {test_result['test_class_2_acc']:.4f}")
    
    best_model_path = checkpoint_callback.best_model_path
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹ä¿å­˜è·¯å¾„: {best_model_path}")
    
    # ä¿å­˜æ¨¡å‹ç”¨äºæ¨ç†
    print("\nğŸ’¾ ä¿å­˜æ¨¡å‹ç”¨äºæ¨ç†...")
    # ä»æœ€ä½³æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹
    best_model = ClassificationStockPredictor.load_from_checkpoint(
        best_model_path,
        n_features=6,
        d_emb=768,
        d_hidden=d_hidden,
        max_ids=87,
        n_blocks=n_blocks,
        d_head=d_hidden // n_head,
        n_head=n_head,
        dropout=dropout,
        use_linear_att=True,
        rotary_emb_list=[2],
        ignore_list=None,
        mode=0,
        lr=learning_rate,
        weight_decay=1e-4
    )
    save_model_for_inference(best_model)
    create_inference_script()
    
    return results, best_model_path


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸‰åˆ†ç±»è‚¡ç¥¨é¢„æµ‹æ¨¡å‹è®­ç»ƒï¼ˆ3å¤©çª—å£ï¼‰")
    print("="*50)
    print("ğŸ“‹ é…ç½®:")
    print("   - æ ‡ç­¾: 3å¤©å¹³å‡æ”¶ç›Š")
    print("   - åˆ†ç±»: æ¶¨/è·Œ/å¹³ (3ç±»)")
    print("   - çª—å£: 3å¤©")
    print("   - é˜ˆå€¼: Â±1%")
    print("="*50)
    
    try:
        result, model_path = train_model()
        print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
        print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {result}")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 