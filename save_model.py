import torch
import os
import json
from datetime import datetime
from src.model import StockPredictor
from src.data import StockNetDataModule
import lightning as L

class ClassificationStockPredictor(StockPredictor):
    """åˆ†ç±»è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ - é¢„æµ‹æ¶¨è·Œæ–¹å‘"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # ä¿®æ”¹è¾“å‡ºå±‚ä¸º3åˆ†ç±»ï¼ˆæ¶¨ã€è·Œã€å¹³ï¼‰
        self.head = torch.nn.Sequential(
            torch.nn.Linear(self.d_hidden, self.d_hidden // 2),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3),
            torch.nn.Linear(self.d_hidden // 2, 3)  # 3åˆ†ç±»
        )

def load_best_model(model_path):
    """åŠ è½½æœ€ä½³æ¨¡å‹"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ¨¡å‹é…ç½®
    model_config = {
        'n_features': 6,
        'd_emb': 768,
        'd_hidden': 128,
        'max_ids': 87,
        'n_blocks': 4,
        'd_head': 32,
        'n_head': 4,
        'dropout': 0.3,
        'use_linear_att': True,
        'rotary_emb_list': [2],
        'ignore_list': None,
        'mode': 0,
        'lr': 5e-5,
        'weight_decay': 1e-4
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = ClassificationStockPredictor(**model_config)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location='cpu')
    model.load_state_dict(checkpoint['state_dict'])
    model.eval()
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    return model

def save_model_for_inference(model, save_dir="saved_models"):
    """ä¿å­˜æ¨¡å‹ç”¨äºæ¨ç†"""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # åˆ›å»ºæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜æ¨¡å‹æ–‡ä»¶
    model_filename = f"stock_predictor_{timestamp}.pth"
    model_path = os.path.join(save_dir, model_filename)
    
    # ä¿å­˜æ¨¡å‹çŠ¶æ€
    torch.save({
        'model_state_dict': model.state_dict(),
        'model_config': {
            'n_features': 6,
            'd_emb': 768,
            'd_hidden': 128,
            'max_ids': 87,
            'n_blocks': 4,
            'd_head': 32,
            'n_head': 4,
            'dropout': 0.3,
            'use_linear_att': True,
            'rotary_emb_list': [2],
            'ignore_list': None,
            'mode': 0
        },
        'model_type': 'classification',
        'num_classes': 3,
        'class_names': ['æ¶¨', 'è·Œ', 'å¹³'],
        'accuracy': 0.6809,  # æµ‹è¯•å‡†ç¡®ç‡
        'save_time': timestamp
    }, model_path)
    
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # ä¿å­˜æ¨¡å‹ä¿¡æ¯
    info_filename = f"model_info_{timestamp}.json"
    info_path = os.path.join(save_dir, info_filename)
    
    model_info = {
        'model_path': model_path,
        'model_type': 'classification',
        'num_classes': 3,
        'class_names': ['æ¶¨', 'è·Œ', 'å¹³'],
        'accuracy': 0.6809,
        'save_time': timestamp,
        'model_config': {
            'n_features': 6,
            'd_emb': 768,
            'd_hidden': 128,
            'max_ids': 87,
            'n_blocks': 4,
            'd_head': 32,
            'n_head': 4,
            'dropout': 0.3
        },
        'usage_instructions': {
            'input_format': 'æ—¶é—´åºåˆ—æ•°æ® (OHLCV) + BERTåµŒå…¥ + è‚¡ç¥¨ID',
            'output_format': '3åˆ†ç±»æ¦‚ç‡ (æ¶¨/è·Œ/å¹³)',
            'prediction_threshold': '0.5% å˜åŒ–é˜ˆå€¼'
        }
    }
    
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_path}")
    
    return model_path, info_path

def create_inference_script(save_dir="saved_models"):
    """åˆ›å»ºæ¨ç†è„šæœ¬"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    script_filename = f"inference_{timestamp}.py"
    script_path = os.path.join(save_dir, script_filename)
    
    script_content = '''import torch
import numpy as np
from src.model import StockPredictor
from src.data import StockNetDataModule

class ClassificationStockPredictor(StockPredictor):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.head = torch.nn.Sequential(
            torch.nn.Linear(self.d_hidden, self.d_hidden // 2),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.3),
            torch.nn.Linear(self.d_hidden // 2, 3)
        )

def load_model(model_path):
    """åŠ è½½ä¿å­˜çš„æ¨¡å‹"""
    checkpoint = torch.load(model_path, map_location='cpu')
    config = checkpoint['model_config']
    
    model = ClassificationStockPredictor(**config)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    return model

def predict_stock(model, x_ts, x_emb, x_id):
    """é¢„æµ‹è‚¡ç¥¨æ¶¨è·Œ"""
    with torch.no_grad():
        predictions = model(x_ts, x_emb, x_id)
        probabilities = torch.softmax(predictions, dim=-1)
        predicted_class = torch.argmax(probabilities, dim=-1)
        
    return {
        'probabilities': probabilities.numpy(),
        'predicted_class': predicted_class.numpy(),
        'class_names': ['æ¶¨', 'è·Œ', 'å¹³']
    }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åŠ è½½æ¨¡å‹
    model_path = "stock_predictor_20241220_123456.pth"  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    model = load_model(model_path)
    
    # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
    # x_ts: æ—¶é—´åºåˆ—æ•°æ® [batch_size, num_stocks, seq_len, features]
    # x_emb: BERTåµŒå…¥ [batch_size, num_stocks, seq_len, 768]
    # x_id: è‚¡ç¥¨ID [batch_size, num_stocks]
    
    print("æ¨¡å‹åŠ è½½å®Œæˆï¼Œå¯ä»¥å¼€å§‹é¢„æµ‹ï¼")
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… æ¨ç†è„šæœ¬å·²åˆ›å»º: {script_path}")
    return script_path

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ä¿å­˜æ¨¡å‹...")
    
    # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹è·¯å¾„
    model_paths = [
        "experiments/improved_data_direction/weights/best-epoch=01-val_accuracy=0.6809.ckpt",
        "experiments/improved_data_direction/weights/best-epoch=00-val_accuracy=0.6809.ckpt",
        "lightning_logs/version_*/checkpoints/*.ckpt"
    ]
    
    best_model_path = None
    for path in model_paths:
        if os.path.exists(path):
            best_model_path = path
            break
    
    if not best_model_path:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        print("è¯·ç¡®ä¿å·²ç»è¿è¡Œè¿‡ train_with_improved_data.py å¹¶æˆåŠŸè®­ç»ƒ")
        return
    
    try:
        # åŠ è½½æ¨¡å‹
        model = load_best_model(best_model_path)
        
        # ä¿å­˜æ¨¡å‹
        save_dir = "saved_models"
        model_path, info_path = save_model_for_inference(model, save_dir)
        
        # åˆ›å»ºæ¨ç†è„šæœ¬
        script_path = create_inference_script(save_dir)
        
        print("\nğŸ‰ æ¨¡å‹ä¿å­˜å®Œæˆï¼")
        print(f"ğŸ“ ä¿å­˜ç›®å½•: {save_dir}")
        print(f"ğŸ“„ æ¨¡å‹æ–‡ä»¶: {os.path.basename(model_path)}")
        print(f"ğŸ“„ æ¨¡å‹ä¿¡æ¯: {os.path.basename(info_path)}")
        print(f"ğŸ“„ æ¨ç†è„šæœ¬: {os.path.basename(script_path)}")
        
        print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
        print("1. æ¨¡å‹æ–‡ä»¶ (.pth) åŒ…å«äº†è®­ç»ƒå¥½çš„æƒé‡")
        print("2. æ¨¡å‹ä¿¡æ¯ (.json) åŒ…å«äº†æ¨¡å‹é…ç½®å’Œä½¿ç”¨è¯´æ˜")
        print("3. æ¨ç†è„šæœ¬ (.py) æä¾›äº†åŠ è½½å’Œé¢„æµ‹çš„ç¤ºä¾‹ä»£ç ")
        print("4. å‡†ç¡®ç‡: 68.09% (ä¸‰åˆ†åˆ†ç±»)")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 